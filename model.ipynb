{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'arg_quality_rank_30k.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate each element's argument and non-argument probabilities & add to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"addy88/argument-classifier\")\n",
    "arg_model = AutoModelForSequenceClassification.from_pretrained(\"addy88/argument-classifier\")\n",
    "\n",
    "import torch\n",
    "\n",
    "# Function to classify an argument and return probabilities\n",
    "def classify_argument(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Get the model output\n",
    "    outputs = arg_model(**inputs)\n",
    "\n",
    "    # Get the predicted probabilities\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # Return probabilities as a list\n",
    "    return probs.tolist()[0]\n",
    "\n",
    "# Apply the function to each argument in the dataset\n",
    "df[['non_argument_prob', 'argument_prob']] = df['argument'].apply(lambda x: pd.Series(classify_argument(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate similarity between topic and argument & add to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Initialize the model\n",
    "sim_model = SentenceTransformer('annakotarba/sentence-similarity')\n",
    "\n",
    "\n",
    "# Function to calculate similarity between argument and topic\n",
    "def calculate_similarity(row):\n",
    "    argument = row['topic']\n",
    "    topic = row['argument']\n",
    "\n",
    "    # Encode the sentences\n",
    "    topic_embedding = sim_model.encode(topic, convert_to_tensor=True)\n",
    "    argument_embedding = sim_model.encode(argument, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_score = util.pytorch_cos_sim(topic_embedding, argument_embedding)\n",
    "\n",
    "    # Return the similarity score\n",
    "    return cosine_score.item()\n",
    "\n",
    "\n",
    "# Apply the function to each row in the dataset\n",
    "df['similarity_score'] = df.apply(calculate_similarity, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save new dataset and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download and save argument classification model\n",
    "arg_model_name = \"addy88/argument-classifier\"\n",
    "arg_tokenizer = AutoTokenizer.from_pretrained(arg_model_name)\n",
    "arg_model = AutoModelForSequenceClassification.from_pretrained(arg_model_name)\n",
    "arg_tokenizer.save_pretrained(\"./local_models/argument-classifier\")\n",
    "arg_model.save_pretrained(\"./local_models/argument-classifier\")\n",
    "\n",
    "# Download and save sentence similarity model\n",
    "sim_model_name = \"annakotarba/sentence-similarity\"\n",
    "sim_model = SentenceTransformer(sim_model_name)\n",
    "sim_model.save(\"./local_models/sentence-similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame back to a CSV file\n",
    "output_file_path = 'augmented-arg-data.csv'\n",
    "df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceeding with new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_name = 'augmented-arg-data.csv'\n",
    "df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train, val, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "train_df = df[df['set'] == 'train']\n",
    "val_df = df[df['set'] == 'dev']\n",
    "test_df = df[df['set'] == 'test']\n",
    "\n",
    "# Define the feature columns and target column\n",
    "feature_columns = ['argument_prob', 'similarity_score']\n",
    "target_column = 'WA'\n",
    "\n",
    "# Split each set into X and Y\n",
    "X_train = train_df[feature_columns]\n",
    "Y_train = train_df[target_column]\n",
    "\n",
    "X_val = val_df[feature_columns]\n",
    "Y_val = val_df[target_column]\n",
    "\n",
    "X_test = test_df[feature_columns]\n",
    "Y_test = test_df[target_column]\n",
    "\n",
    "# Print the first few rows of X and Y for each set to verify\n",
    "print(\"X_train:\\n\", X_train)\n",
    "print(\"Y_train:\\n\", Y_train)\n",
    "print(\"X_val:\\n\", X_val)\n",
    "print(\"Y_val:\\n\", Y_val)\n",
    "print(\"X_test:\\n\", X_test)\n",
    "print(\"Y_test:\\n\", Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Quality Metric using Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best parameters and estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_gb_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on validation set\n",
    "Y_val_pred = best_gb_model.predict(X_val)\n",
    "mse = mean_squared_error(Y_val, Y_val_pred)\n",
    "r2 = r2_score(Y_val, Y_val_pred)\n",
    "print(f\"Best Validation Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"Best Validation R^2 Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Extract test features and target\n",
    "X_test = test_df[['argument_prob', 'similarity_score']]\n",
    "Y_test = test_df['combined_quality']\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_test_pred = best_gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_mse = mean_squared_error(Y_test, Y_test_pred)\n",
    "test_r2 = r2_score(Y_test, Y_test_pred)\n",
    "\n",
    "print(f\"Test Mean Squared Error: {test_mse:.4f}\")\n",
    "print(f\"Test R^2 Score: {test_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on individual inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load model directly\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"addy88/argument-classifier\")\n",
    "arg_model = AutoModelForSequenceClassification.from_pretrained(\"addy88/argument-classifier\")\n",
    "sim_model = SentenceTransformer('annakotarba/sentence-similarity')\n",
    "\n",
    "\n",
    "# Function to calculate similarity between argument and topic\n",
    "def calculate_similarity(argument, topic):\n",
    "    # Encode the sentences\n",
    "    topic_embedding = sim_model.encode(topic, convert_to_tensor=True)\n",
    "    argument_embedding = sim_model.encode(argument, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_score = util.pytorch_cos_sim(topic_embedding, argument_embedding)\n",
    "\n",
    "    # Return the similarity score\n",
    "    return cosine_score.item()\n",
    "\n",
    "\n",
    "# Function to classify an argument and return probabilities\n",
    "def classify_argument(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Get the model output\n",
    "    outputs = arg_model(**inputs)\n",
    "\n",
    "    # Get the predicted probabilities\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # Return probabilities as a list\n",
    "    return probs.tolist()[0][1]\n",
    "\n",
    "\n",
    "# Define a function to predict the score of an argument\n",
    "def predict_argument_score(argument, topic):\n",
    "    argument_prob = classify_argument(argument)\n",
    "    similarity_score = calculate_similarity(argument, topic)\n",
    "\n",
    "    # Prepare the input features for the model\n",
    "    X_test = [[argument_prob, similarity_score]]\n",
    "\n",
    "    # Predict the accuracy score\n",
    "    accuracy_score = best_gb_model.predict(X_test)\n",
    "\n",
    "    return accuracy_score[0]  # Return the predicted accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "argument = \"cannabis increases drug trafficking and violence in the streets\"\n",
    "topic = \"We should legalize cannabis\"\n",
    "\n",
    "accuracy_score = predict_argument_score(argument, topic)\n",
    "\n",
    "print(f\"The predicted accuracy score for the argument is: {accuracy_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(best_gb_model, 'kelly-model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
